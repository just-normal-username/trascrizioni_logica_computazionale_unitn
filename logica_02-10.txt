2025-10-14 12:03:01 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...
Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cu126. Bad things might happen unless you revert torch to 1.x.
2025-10-14 12:03:06 - whisperx.transcribe - INFO - Performing transcription...
Transcript: [5.988 --> 35.941]  in rappresentazioni interne nel caso delle persone, nel nostro cervello, nel nostro caso di fare informatica, di fare sistemi, i vari sistemi di teoria artificiale o sistemi informati che noi facciamo. Secondi due invece sono i processi di ragionamento a cui inizieremo a parlare la settimana prossima e come ho detto la volta scorsa
Transcript: [36.937 --> 66.012]  La prima famiglia di logiche che Þ stata di fatto inventata dagli informatici che ha permesso di ragionare su tutto ci‗ che viene memorizzato ad esempio in un database, le logiche del mondo, World Logics, noi ragioniamo e facciamo conseguenze da quello che sappiamo. Nelle Reasoning Logics vedremo i vari algoritmi che ci permetteranno di
Transcript: [67.21 --> 93.957]  giungere a conclusioni su quello che noi non sappiamo in modo corretto e completo. Corretto e completo rispetto a cosa? Rispetto ai nostri modelli del mondo, ok? I nostri modelli del mondo, nella lezione scorsa, perchÚ chiaramente noi dobbiamo comunque partire da qualcosa, i nostri modelli del mondo, nella lezione scorsa abbiamo detto che rappresentiamo in teoria degli insieme e abbiamo fatto tutta una serie di
Transcript: [95.611 --> 125.108]  passo a passo costruzione in cui abbiamo fatto vedere come da altre rappresentazioni visive si poteva costruire degli insiemi che le rappresentavano e abbiamo anche fatto l'affermazione che avevo fatto in precedenza che la teoria degli insiemi Þ universale. Come vedete poi questa citazione Þ una qualunque situazione nel mondo dove voi percepite Þ rappresentabile
Transcript: [125.969 --> 155.534]  in teoria dell'insieme e nella volta scorsa abbiamo parlato delle varie approssimazioni che si fanno distinguiamo correnza e dovete di una cosa dalla cosa che viene vista pi¨ volte insieme di entitÓ, le cose le chiamate entitÓ e poi abbiamo fatto relazioni fra identitÓ, proprietÓ e cosý via. Oggi affrontiamo il secondo livello
Transcript: [155.872 --> 178.906]  perchÚ voi ricordate che nelle prime lezioni io ho distinto la rappresentazione del mondo in rappresentazioni analogiche, che sono quelle che in qualche maniera, come ha detto, formalizziamo ogni modello, e rappresentazioni linguistiche, quelle usando il linguaggio. Quindi, di fatto, oggi dobbiamo fare due passi. Prima dobbiamo darci le rappresentazioni linguistiche, formalizzarle,
Transcript: [179.902 --> 208.572]  e poi dobbiamo creare questo link che Þ un link di caso-effetto nella nostra mente e quindi anche nei nostri algoritmi tale per cui se io dico casa tu ti immagini una casa se tu vedi una casa o una foto dici casa cioÞ un mapping e chiaramente noi per poter fare direzioni di correttezza e correttezza dobbiamo formalizzare questo mapping questa parte qui noi la dividiamo in due parti una prima lezione oggi
Transcript: [211.087 --> 240.584]  in cui ci diamo l'aspetto linguistico, introduciamo il concetto di linguaggio e di lingueria. Ovviamente, l'idea di linguaggio sicuramente l'avete fatta a compilatore, questo Þ un linguaggio particolare, sono quei linguaggi che noi usiamo per descrivere il mondo. In termini della direttura di Chomsky, sono linguaggi facili, di tipo, quanti linguaggi vogliono usare, per tutta la complessitÓ, sono linguaggi di tipo 2, semplicemente 1, in pochissimi casi,
Transcript: [241.9 --> 258.438]  e poi inizieremo oggi, forse noi domani finiremo di definire il passo formale che ci permette di far sý che queste teorie che sono qua
Transcript: [260.26 --> 289.606]  insieme ai modelli fanno i modelli del mondo. Il modello del mondo per noi Þ, come definiamo fra oggi e domani, Þ un qualcosa che o me lo fai vedere o te lo dico, io sono in grado di dirÓ, Þ quello, e poi nella parte dopo, una volta che l'ho detto, sono anche in grado di ragionarlo. Questa l'abbiamo giÓ vista esattamente la prima della lezione scorsa,
Transcript: [291.715 --> 315.155]  e avevamo detto la volta scorsa chiaramente c'Þ stato un problema di ambiguitÓ, tutti sapete che il vero problema Þ quello dell'ambiguitÓ, il vero problema Þ che noi si formalizza in logica ed Þ il motivo per cui ci serve la semantica e quando noi diciamo una parola o qualcosa Þ ambiguo quello che diciamo o comunque a volte non Þ neanche chiaro.
Transcript: [315.897 --> 342.205]  e quindi come anche noi risolviamo le interagibilitÓ formalizziamo questo, formalizziamo questo, questo Þ l'aspetto della teoria, questo Þ l'aspetto del modello e poi formalizziamo il link, questo Þ il modello. Oggi ci concentriamo sull'aspetto della teoria. Tra parentesi, come vedremo giÓ domani, come inizieremo anche oggi,
Transcript: [343.538 --> 372.563]  ed Þ il motivo per cui vi Þ stata fatta un'esercitazione su questo, l'unica esercitazione che aveva fatto due settimane fa, questo modello del mondo di cui parleremo, vi faremo vedere nelle prossime esercitazioni, comprende e formalizza tutti i linguaggi che voi avete visto fino adesso, di specifico. E anche il database, tabelle e cosý via. E questo di fatto ci dice, e chiaramente non Þ un caso,
Transcript: [373.778 --> 400.795]  chi dice che in qualche maniera data, come farete poi le esercitazioni, una volta che abbiamo capito in realtÓ come sono costruiti questi vari linguaggi, intendo il linguaggio tabulare dei decadenti, intendo gli R-model, gli RML model, gli RML non lo facciamo per mancanza di tempo, ma comunque Þ la stessa cosa, la logica vi dÓ effettivamente un metodo per ragionare sulle nostre presentazioni del mondo.
Transcript: [405.605 --> 435.457]  Quindi il passaggio Þ dal modello alla teoria, quindi dal modello non linguistica alla pretenzione linguistica del mondo. Ovviamente quando voi parlate, io parlo, ho un mio modello in testa, quello che si chiama Nintendo's model, modello in testa. Per‗ io quello che c'ho in testa, a diversi dei computer, non te lo riesco a far vedere, posso solo descriverlo.
Transcript: [436.874 --> 460.887]  C'Þ un teorema che dice che una qualunque tua descrizione, che vedremo pi¨ avanti, e che Þ connessione esattamente della seconda lezione, qualunque descrizione tu dai Þ complessicamente incompleta, ovvero sia, ci sono infiniti modelli di lato a testa che corrispondono alla stessa descrizione. E' un teorema, un fatto. Poi, nell'ultima lezione lo faremo e lo vedremo.
Transcript: [462.102 --> 488.377]  Allora la gente dice ok, per‗ io in realtÓ c'ho il mio modello inteso. Il mio modello inteso Þ tale per cui quando io costruisco questa teoria, questa rappresentazione fisica della teoria, deve essere un qualcosa che la teoria descrive. E ovviamente, lo vedremo pi¨ avanti nella lezione, puoi dire che la descrive correttamente,
Transcript: [491.043 --> 520.81]  Nella misura in cui noi abbiamo il modello con un oggetto formalizzato, noi questi teorici li possiamo dimostrare. Ovviamente, voi ricorderete, che ho detto la volta scorsa e scritto anche sulle slide, che quando tu passi dal modello della foto al modello di segnistico
Transcript: [521.772 --> 550.628]  In realtÓ c'Þ un sacco di scelte, ok? Il modello di MIST non Þ che ripresenta l'insieme. Quello che ho detto prima Þ che l'integrimento dell'insieme Þ un modello di rappresentazione universale, Þ una conclusione del mondo, ma non ho detto che rappresenta completamente, ok? Infatti, in questo teorema non facciamo che dice che si integri a dei numeri e che il modello non pu‗ rappresentare completamente, in termini di integrimento dell'insieme, quello che noi vediamo.
Transcript: [551.067 --> 579.181]  Quindi qui cominciamo a vedere perchÚ pu‗ avere senso forse la logica da qualunque cosa noi vediamo e rappresentiamo facciamo fare una macchina, facciamo portarmi per una scelta pi¨ divisiva quella che vogliamo la macchina non lo pu‗ rappresentare completamente quando poi lo liftiamo a livello di descrizione linguistica Þ dato da un modello c'Þ una... ci sono infinite rappresentazioni linguistiche che lo descrivono e se stesse
Transcript: [579.67 --> 595.162]  in questo Þ il problema, ed Þ il motivo, questi aspetti qua, che prendiamo cosý tanto,
Transcript: [602.57 --> 621.065]  7, 8, 10 lezioni e cominciare a descrivere tabelle di veritÓ, vero o falso, facevamo gli algoritmi, sicuramente questo bastava per chi di voi faceva software engineering e formal methods, ma chi da grande farÓ modellazione, sistemi, AI, questo passaggio di modellazione che
Transcript: [627.123 --> 653.988]  Þ fondamentale cosý almeno la gente se lo sapesse smetterebbe di dire che avremmo le macchine pi¨ intelligenti degli uomini, che Þ semplicemente impossibile per quanto detto. Si pu‗ dimostrare che Þ impossibile avere tanta gente che confronto il fatto che una macchina, tanti pi¨ fatti di noi, semplicemente abbiano dato pi¨ dati, perchÚ ha tutto il lavoro in pancia, con il fatto che Þ pi¨ intelligente. Chiaramente si pu‗ decidere cosa vuol dire intelligente, ma sicuramente noi possiamo fare macchine
Transcript: [658.51 --> 678.507]  molti pi¨ fatti di noi, ma sicuramente non potremmo mai fare macchine che sono in grado di ragionare come ragioniamo noi, anche perchÚ tra parentesi non sappiamo com'Þ la vita in realtÓ. Non abbiamo i motivi per cui questa rappresentazione venga fatta. Da noi, come persone, come individui o anche come gruppi di individui. Detto questo,
Transcript: [679.874 --> 708.882]  E' chiaro che se noi dobbiamo formalizzare, far diventare tutta logica matematica, io appunto ci poniamo di linguaggio. Allora, prima cosa, non vi sto dicendo niente di nuovo. Queste rappresentazioni fanno parte del vostro vissuto quotidiano. Insisto questo per far chiaro, non Þ che vi sto dicendo che c'Þ una cosa esoterica, la logica che fa davvero di veritÓ, no. La logica formalizza ci‗ che voi conoscete giÓ. Il problema qui Þ semplicemente formalizzarlo
Transcript: [709.169 --> 736.692]  e riuscire a ragionare in maniera corretta e completa. E questa Þ tutta l'idea di questo corso. Poi alla fine faremo anche i tremi di algoritmi, quello che volete. Ma il contenuto principale Þ di capire che in ogni volta che fai una rappresentazione fai delle scelte. La prima scelta Þ linguaggio. Fino adesso voi le linguaglie le avete usate, sin da quando bambini, parlate e raccontate. L'altro capisce, il linguaggio naturale Þ un linguaggio di rappresentazione. Ma qual Þ il problema?
Transcript: [737.519 --> 759.068]  La sintesi Þ andata informalmente su un libro, ma non ci sono elementari. La gente ha provato a fare algoritmi generativi, di grammatica generativa, che generavano lo spazio per distinguere le linguaggie, ma abbiamo fallito. Sono linguaggi pi¨ facili da capire, perchÚ la gente l'ha fatta, le abbiamo dette alle volte,
Transcript: [766.19 --> 790.777]  sono linguaggi ancora pi¨ semplici che rappresentano, questi sono linguaggi che non rappresentano i dati, che sono ultimi per la specifica, rappresentano in qualche modo lo schema dei dati, come vedremo nelle lezioni di domani, e poi sono linguaggi, database nazionali che quando uscirono fecero un salto di qualitÓ, non furono pi¨ un tipo di database, c'erano tre tipi, vari tipi di database in precedenza, i database nazionali
Transcript: [791.232 --> 813.862]  con il fatto del loro formato tabulare, sono quelli che ci hanno permesso per vent'anni sinceramente di risolvere il problema della presentazione dei dati corretta e completa nelle applicazioni corporate, applicazioni che si usano normalmente e che hanno, perchÚ, perchÚ funzionano, perchÚ quando tu fai un'applicazione corporate ad esempio S3 nel vostro caso
Transcript: [814.098 --> 840.743]  quando tu disegni S3 sai esattamente tutte le condizioni dentro cui funzionerÓ quindi sapendo tutto fai le specifiche e se c'Þ un errore lo riesci a beccare al massimo c'Þ un errore di che inserisci d'altro ma non Þ che S3 quando l'ho disegnato non sapevo cosa doveva fare tant'Þ vero che l'abbiamo disegnato a trento e quindi l'abbiamo disegnato noi quindi sappiamo esattamente chiaramente quando tu fai un sistema di AI
Transcript: [843.612 --> 871.321]  del motivo per cui, oppure quando fai un sistema che esercizia un treno e devi garantire che il treno metto in precedenza non si scontra pi¨ veloce con il treno davanti, per‗ muoversi, quindi l'idea di un treno Þ di andare il pi¨ veloce possibile, ma tale per cui se c'Þ qualcosa a stop si ferma pi¨ velocemente davanti. Queste sono le specifiche di questo software.
Transcript: [871.81 --> 900.059]  ed Þ un sistema aperto, ed Þ un sistema in cui non ti basta dire, ah vabbÞ, sono studenti e gli manca un esame, tanto quello correbbe, no. Allora, quando arrivi in questo livello di dettaglio, devi andare oltre il sezionale risultato che, non ho portato, in informatica e nei tabelli relazionali. E quindi parliamo di linguaggi logici.
Transcript: [904.379 --> 931.868]  quindi passiamo dai linguaggi utili per i linguaggi logici. E cosa saranno i linguaggi logici? Sono linguaggi logici a cui definiremo formalmente, in astratto, poi dalla prossima lezione entriremo nel dettaglio dei vari linguaggi, ma saranno tutti linguaggi che sottiliscono queste definizioni, sono linguaggi che, come ho detto in precedenza, hanno una funzione di mapping
Transcript: [937.235 --> 966.04]  tu lo fai, lo sai, oppure per fare un linguaggio logico devi garantire la design time che questo mapping da linguaggio al modello esiste e come lo fai? Beh, abbiamo parlato da ci‗, non c'Þ niente da inventare Cos'Þ? Un alfabeto insieme di information rules, il verbo di informazione, BNF, niente di pi¨ La cosa interessante Þ essere, perchÚ Þ la cosa nuova che
Transcript: [967.897 --> 997.529]  non nuove, nel senso un passo importante che proprio in questo linguaggio dotifichiamo l'insieme delle frasi che sono ben formate. Voi ricordate che avete fatto combinatore immagini, ho dato una PNF e tu hai un algoritmo, un traduttore, che per me Þ la prima fase di traduzione dalla forma esterna alla forma interna, in cui gli dai una cosa in input e ti dice, sý va bene, l'ho riconosciuta, l'ho riconosciuta.
Transcript: [997.85 --> 1027.077]  non avevano riconosciuto gli errori di formazione. Tutti questi linguaggi sono linguaggi, quindi natural language, language Java, sono tutti esempi di linguaggi. Ovviamente non tutti sono linguaggi logici. PerchÚ noi, come vedremo adesso, il nostro fondamentale Þ dire
Transcript: [1028.798 --> 1054.938]  Come vi ho detto, lo formalizzeremo adesso, io dico oggi piove, prima di tutto dico una cosa che Þ vera o falsa e seconda cosa guardo fuori e dico che non Þ che Þ falsa. CioÞ prima, come posso dire, oggi non piove, oggi c'Þ il sole, guardo fuori e vera.
Transcript: [1055.208 --> 1074.968]  per‗ prima vi devo darlo spazio in tutte le frasi, perchÚ oggi vedo che piove, domani vedo che c'Þ il sole, e viceversa. Quindi tutto l'elemento del linguaggio logico Þ arrivare a definire queste insieme di frasi, sentenze, tale per cui quando le mappe
Transcript: [1082.377 --> 1108.887]  Ed Þ esattamente il motivo per cui quando sono arrivato qua, vedete tutte queste esempli che ho fatto, tutte queste voi potevate dire se c'Þ una banca, se c'Þ un'albero, se c'Þ una banana, se c'Þ una banca che manda banale, non lo so perchÚ di quale banca mi parleremo? Di quale banca di cibo sto parlando?
Transcript: [1109.377 --> 1139.009]  per‗ modulo questo, queste sono tutte sentenze in un linguaggio come vedremo fra un minuto quindi il punto fondamentale Þ esattamente definire lo spazio di questi linguaggi logici questi spazi che vengono generati da un'altra mente insieme a diretta informazione e che vi dÓ come output della fondazione sul mondo tale per cui domani vi dimostrer‗ come sarÓ possibile matematicamente definirsi i sommi logici
Transcript: [1143.633 --> 1173.485]  Allora la prima cosa Þ mapparlo sul mondo, ok? Il concetto che abbiamo fatto, e qui sto usando, sto introducendo e riprendendo il concetto che abbiamo fatto due lezioni fa. Cos'Þ una parola? Una parola, una parola casa, anzi ho fatto fare la parola, la pi¨ famosa Þ, bene qui in inglese,
Transcript: [1176.691 --> 1194.14]  Questa Þ una parola che io avr‗ nel mio linguaggio ed Þ una parola che user‗ per fare delle frasi. Ovviamente voi sapete cosa vuol dire bank, la riva del fiume,
Transcript: [1202.729 --> 1231.349]  Ben, che Þ una parola che per‗ ha almeno dei significati, che Þ sul fiume, riva del fiume, scritta in italiano, o banca. Se io questo lo chiamo numero uno e questo lo chiamo numero due, o seppure questo lo chiamo benef numero uno e questo lo chiamo benef numero due, questo Þ il concetto.
Transcript: [1239.787 --> 1266.128]  a quello che vi sapevo di precedenza su Word, la gente ha fatto Word, che Þ di fatto quello che voi avete sui vocabolari, andate a cercare vocabolari, vocabolari come Word, qual'Þ la differenza? Che Þ in ordine alfabetico, e perchÚ Word non ha fatti in ordine alfabetico? PerchÚ non serviva a niente, appena informatici venivano ad andare a trovare il significato preciso, per‗ di fatto Word non Þ un vocabolario online in cui l'ordine
Transcript: [1266.365 --> 1293.348]  l'ordine dei concetti, come essere ordine alfabetica delle parole, mentre UORN, come l'avete fatto e lo riprenderemo pi¨ avanti quando faremo la formalizzazione di UORN, Þ un vocabolario in cui l'ordine, prima di tutto non Þ lineare, Þ ad albero e ad ag, e secondo Þ sul significato dei concetti, nel senso che il significato del concetto Þ il motivo per cui noi possiamo fare l'ergolitmo. Quindi la prima cosa fondamentale per‗ Þ che in questi linguaggi
Transcript: [1295.778 --> 1323.908]  L'alfabeto sono concetti, non sono parole. Almeno sono parole che denotano concetti, e il concetto denotando la parola. Poi chiaramente noi neanche noi andiamo a dire io sono vicino a Banc 1, o sono sul Banc 1 del Fiume. Noi siamo sempre in linguaggio naturale, manteniamo il significato linguistico, ma questo vuol dire che quando noi passiamo, come abbiamo detto, adesso con chiaro segretario dei dettagli, dalla descrizione linguistica
Transcript: [1324.178 --> 1351.887]  in linguaggio naturale per arrivare alla lotica devo fare questa cosa qua. C'Þ un'intera branca di layout che si chiama world-sensitive navigation che Þ un'area molto pesante che serve a generare da linked world il concetto
Transcript: [1355.735 --> 1385.468]  Quindi a questo punto Þ un insieme di parole tenendo per panore questi concetti che denotano nel modello i percetti. Per‗ la parola fausto o la parola persona non Þ che denota me fausto in tutta la mia vita. Quindi nel passaggio dai percetti
Transcript: [1386.852 --> 1402.9]  anche in termini di AI al singola parola c'Þ un mapping infinito 1. Quindi questo passo Þ un passo in situazione enorme e come ho detto pi¨ volte in passato
Transcript: [1408.621 --> 1436.279]  Quando noi vediamo una foto, l'abbiamo detto la volta scorsa, scegliamo noi la parola, quindi vedendo noi la parola scegliamo noi quello che c'Þ nella foto, ed Þ una scelta vittoria. L'unico vincolo che abbiamo Þ questo, che ogni concetto ha un solo percetto, non c'Þ l'abilitÓ, non c'Þ questo carlo qua, ok? Ma vale il viceversa? Car, possiamo chiamare car, ma possiamo chiamare automobile,
Transcript: [1441.932 --> 1470.873]  PerchÞ? PerchÞ dal punto di vista di sensibilitÓ Þ rilevante, anzi ci dÓ flessibilitÓ. Chiaramente, se per‗ poi tu fai AI, ti vuoi fare AI, e fai di Sirius una semantic, si trova il fatto che la macchina, se non sa che sono la stessa cosa, le pensa con due parole diverse, e magari non riconosce une simili frasi che in realtÓ usano semplicemente due parole diverse per le stesse cose, che Þ il problema classico che esiste. Chiaramente,
Transcript: [1475.227 --> 1503.678]  Se ricordate bene, la volta scorsa ho detto che ci sono sei tipi di percetti, cioÞ percetto istanza, percetto concetto e cosý via. Sei tipi di percetti, sei tipi di concetti. PerchÚ ovviamente quello che tu vuoi, che tu devi avere un meccanismo, e poi lo vediamo bene nella lezione di domani, per‗ di qualunque cosa,
Transcript: [1504.336 --> 1533.58]  che tu fai linguisticamente, puoi scegliere una parola, ma, infatti la dirci in inglese, francese o quello che volete in italiano, ma dato che il mondo Þ l'unico, se il mondo noi lo diciamo che Þ fatto in sei, che Þ organizzato, lo modelliamo, infatti io, usando sei tipi di percetti, se noi vogliamo avere una rappresentazione chiara, dobbiamo avere sei tipi di concetti.
Transcript: [1536.314 --> 1558.083]  e questo infatti Þ la proprietÓ fondamentale che Þ la logica, che Þ la proprietÓ della composizionalitÓ che vedremo estensivamente e che Þ esattamente quella che poi ci permette di fare gli argomenti. Cosa vuol dire? Vuol dire che se io nel modello
Transcript: [1563.483 --> 1590.989]  in questa maniera qua, io nel linguaggio devo avere un concetto per questo, un concetto per questo, e un concetto per questo, e un concetto per come metto insieme. Ed Þ questa la composizione della sintassi che poi ci permetterÓ di dire se noi il linguaggio Þ fatto bene e mantiene questa proprietÓ, ogni qualunque composizione linguistica si mappa in una composizione del modello.
Transcript: [1592.035 --> 1616.588]  Quindi se io ti dico, Fausto vicino al telefono, Fausto, io, telefono, telefono, vicino, Þ una relazione, una relazione binaria. I verdi sono tutti relazioni. Fausto mangia la mela. Fausto parla a voi. Fausto parla da solo. Oggetto e soggetto Þ la stessa cosa. Fausto cammina, ma Þ scelto da Trinx.
Transcript: [1619.93 --> 1643.808]  Quindi qui sono tutti vari esempi che potete vedervi e chiaramente quando io qua metto verbo, nome, verbo, nome Þ perchÚ non casualmente, non casualmente, anche, ovviamente non casualmente, anche in linguaggio naturale le strutture sintattiche si mappono sulla struttura semantica. Per la gente serve una vita facile. Poi chiaramente
Transcript: [1645.175 --> 1674.892]  Come vedremo fra un minuto, se tu fai melia moderna, io devo fare la persona che ho visto l'altro ieri, o la persona che ha mangiato la maglia d'acciaio, che ho visto diventa completamente oggetto, perchÚ la persona che ha mangiato diventa soggetto. Allora la gente fa i linguaggi formali dove l'igna Þ questa ambiguitÓ, la contestualitÓ del linguaggio. Per‗ comunque stiamo sempre parlando di sei tipi di significati,
Transcript: [1681.355 --> 1711.207]  e ovviamente qui possiamo andare veloci abbiamo l'interessante qui a dire questa frase dall'idea della motivo per cui che fa confessione di inguaglio naturale a problemi cioÞ non Þ un problema affatti, un problema ancora io ho risolto anche se adesso mi hanno fatto passi davanti alla gigante perchÚ non Þ solamente bank, bank of the river e bank of an organization e anche che la parola friend qui
Transcript: [1713.029 --> 1740.89]  Cambia percetto, qua Friend Þ un concetto, cioÞ un insieme di persone. Qui Þ una relazione fra due persone. Fausto, amico di Mario, Þ una relazione. Gli amici ti aiutano sempre, Þ un insieme. Ad esempio questa cosa Þ una cosa che via modo non ti permette di fare, perchÚ tu ometti il nome
Transcript: [1741.261 --> 1769.678]  o fa diventare un tipo, un insieme, o fa diventare una relazione. Quindi il model ti lascia sempre l'opportunitÓ sulla singola parola, ma la struttura sintattica Þ un grande passo in avanti, infatti Þ una grammatica di tipo 1. Tu, per esempio, lo puoi usare in un modo o nell'altro, ma non lo puoi usare in qualsiasi altra maniera. Lo puoi usare come relazione o lo puoi usare come concetto o come intaglio.
Transcript: [1775.888 --> 1801.083]  Bene, ora ci siamo dati l'alfabeto e chiaramente l'alfabeto, vi ho fatto vedere gli esempi, ve l'ho fatto per esempio perchÚ non posso farlo formalmente, perchÚ la scelta precisa dipende dalla logica, dipende dal formalismo. Ancora non da me, ma la volta prossima la prima cosa che far‗ vi dar‗ la BNF, Þ chiaro?
Transcript: [1801.673 --> 1829.146]  perchÚ una volta stabilito che noi comunque abbiamo sempre e solo sei tipi di concetti e stabilito che comunque se in senso e solo noi mettiamo insieme per formare queste sentenze che noi chiamiamo asserzioni, adesso in diversi linguaggi si differenziano su come li metti insieme questi concetti e questi concetti estrassificati che gli dai. Quindi in qualche maniera quello che vi sto dicendo adesso vi sto dando un meccanismo che Þ universale
Transcript: [1829.872 --> 1852.197]  Sto dicendo che per qualunque linguaggio di programmazione, linguaggio di programmazione c'Þ una dimensione temporale, qualunque linguaggio di modellistica voi fate, farete sempre queste tre cose qua. E ora facciamo la soluzione. Se noi abbiamo dato questa roba qui, noi esattamente insieme a S, adesso ho chiamato
Transcript: [1855.808 --> 1883.905]  infatti non mi piace la versione dove c'Þ la S, Þ l'insieme, ah no questa Þ l'alfabeto, cos'Þ l'alfabeto? L'alfabeto Þ l'insieme delle words, ossia di quei singoli sei tipi che vi ho fatto vedere, che sono quelli che corrispondono ai percetti che tu percepisci. E com'Þ che li mettiamo insieme? Comunque dai regoli di formazione che avete visto.
Transcript: [1896.443 --> 1925.587]  che facciamo? Vi ricordate che abbiamo detto cos'era un dominio? Un dominio era una tripla dove c'era che cosa? L'universo che era l'insieme degli elementi del dominio, dei unit. C, l'insieme dei concetti classi che abbiamo chiamate come tu raccogli di tonitÓ
Transcript: [1926.127 --> 1955.067]  sulla base di ci-di-tu e le relazioni fra di loro. Dove pure, avevamo detto a fine lezione, le chiamiamo entitÓ per non chiamarle unit, perchÚ di fatto uno dei problemi che c'Þ, che comunque Þ sempre linguaggio naturale, non Þ un problema quando sai cosa parli, la gente confonde il concetto di relazione nel linguaggio con il concetto di proprietÓ, il concetto di unit, il concetto di entitÓ, con una misura in cui noi sappiamo se noi siamo in livello semantico o in livello linguistico,
Transcript: [1955.557 --> 1983.215]  non Þ un problema ed Þ un'approssimazione che manteniamo anche noi per mantenerci pi¨ vicini all'altro. Allora vedete che qui noi in qualche maniera, dato un certo linguaggio, ci prendiamo un alfabeto e ci prendiamo delle nuove informazioni. Quindi queste nuove informazioni
Transcript: [1985.948 --> 2010.755]  con questo alfabeto, io dovrei avere un alfabeto che mi mappa tutte queste tre qua e poi nelle confrontazioni vediamo come le compongo. Chiaramente, l'abbiamo giÓ detto in precedenza, io chiaramente devo, quando io prendo l'alfabeto
Transcript: [2014.737 --> 2039.358]  che si fa esplicitamente sempre e che si fa informalmente a linguaggio naturale, io quando scelgo l'alfabeto scelgo quello che esicido di vedere nella figura. Una volta che ho scelto gli do il nome. E ovviamente puoi decidere chiaramente se vuoi parlare di persone che sono vicine uso questo.
Transcript: [2055.22 --> 2083.874]  e chiaramente come tu metti le regole di informazione insieme ti luoghi una scelta linguageristica e chiaramente che facciamo? questo Þ il linguaggio naturale tendenzialmente il linguaggio naturale tutte le parole che hai le usi e non c'Þ nessun vincolo oppure fai
Transcript: [2085.005 --> 2108.512]  scegli una BNF, per‗ se voi tornate indietro, sperate, sui livelli naturali, vedete questa frase qua, c'Þ di nuovo queste frasi, quelle che sono vere o false. Se voi tornate indietro, ancora del linguaggio, le origini del... leggiamo la prima frase, cerchiamo il verbo. La prima
Transcript: [2112.545 --> 2142.194]  Allora, vedete, c'Þ l'anterior del subverbo, l'anterior subordinata, no? Allora, il punto fondamentale ti fa l'affermazione, ti dice che una certa azione, discutere, su una certa cosa, su un altro verbo, su una cosa che esista, che sono i passaggi dal Bolzano al Brennero. Allora, prima di tutto, uno potrebbe dire, Þ vero o falso che ci sono questi passaggi dal Brennero? Sý o no? Sý, Þ vero. ╚ vero o falso che
Transcript: [2142.616 --> 2157.128]  Si parla di quella roba lý? Lo leggiamo? Sý, lo so, Þ vero. SarÓ vero, Bert. Se ce lo dice lui ci crediamo. C'ha limiti, ci crediamo. Non c'Þ nessun modo di verificarlo.
Transcript: [2161.853 --> 2190.187]  Vedete, poi, le age sono molto influenzate, a questo Þ preso da Chiquita, dai vicini, Þ vero o no? Io no, per‗ lui dice di sý, mediamente sý. Il punto fondamentale, volevo dire, comunque, anche l'iguaglio naturale la metti pi¨ complicata, quello che vuoi, ma comunque c'Þ questa situazione qua. Questa situazione qua Þ una situazione dove manteniamo l'amiguitÓ sulle parole, sensibilitÓ delle parole,
Transcript: [2190.676 --> 2217.676]  Ma abbiamo eliminato un sacco di complicazioni nella costruzione di quelle frasi che sono vero-false. Ok? Giustamente. Chiaramente adesso noi, la gente, molti di noi, in parte anche io, pensano che, molti pensano che si possa arrivare, tra qualche anno, a una situazione in cui si programma in linguaggio naturale. Gli dici, fatti il programma e te lo fai. Chiaramente,
Transcript: [2222.165 --> 2247.123]  e questi dicono esattamente la stessa cosa. Qual Þ la differenza tra parlare in linguaggio naturale e programmare in Java? Ecco, in linguaggio naturale programma chiunque. In Java li avevi fatto il corso di informatica. Quindi c'Þ tutta questa gente che Þ preoccupata del lavoro che andrete a fare voi. Detto questo, se vogliamo aprendere un altro, diciamo questo e noi la stessa cosa.
Transcript: [2253.282 --> 2278.325]  italiano vero, Fausto, supervisione da lui, non Þ pi¨ vero, ma era vero nel passato e cosý via, sono sempre tripli. Questo Þ il motivo per cui se tu impari come una tecnica di transformare, fare traduzioni da triple a triple, di fatto a questo punto prendi il triple che vuoi. Chiaramente riguardo il naturale Þ pi¨ complicato.
Transcript: [2279.084 --> 2298.878]  ma la tripla che tu hai in arrivo, qualsiasi database, qualsiasi numero di cosa, Þ comunque il tuo linguaggio di programmazione. Se riesci a trovare un compilatore da linguaggio naturale, il tuo linguaggio di programmazione lo troverai veramente in linguaggio naturale fra qualche anno, forse, vediamo.
Transcript: [2299.233 --> 2322.554]  non Þ ovvio. Chiaramente questa Þ l'archivizione di Tammes, funzionava meravigliosamente perchÚ in generale, perchÚ era la designa interna circolettrice, adesso la gente fa gli holographics. Quella di prima rappresenta esattamente la stessa cosa di prima, per‗ Þ pi¨ flessibile perchÚ Þ con grafici. Notare bene che
Transcript: [2323.145 --> 2345.015]  Vedete, Paolo Un Þ sempre il mio... Io faccio questo e voi tanto... Tutto il corso lo faremo sui nodi grafici. Chiaramente qua ci sono entitÓ, che sono i nodi, qui ci sono nodi grafici dove le entitÓ sono nodi. Il concetto Þ che Paolo Þ una persona, lo mettiamo in rosso, lo mettiamo in quello che vogliamo, basta avere il color code e come scrivere forne.
Transcript: [2345.723 --> 2373.989]  Questa Þ una proprietÓ che ha come valore un'entitÓ, no, questa Þ sempre una identitÓ, ecco qui abbiamo una proprietÓ che ha come valore una data, sicuramente una identitÓ che non c'Þ problema, e sono tutte relazioni. In questo tipo di knowledge graph le relazioni sono fede e frecce, l'entitÓ sono i nomi. Rappresenta esattamente la stessa cosa, l'identitÓ bene-razionale,
Transcript: [2374.411 --> 2404.212]  rappresenta esattamente la stessa cosa di un linguaggio naturale ma nella presentazione standard con essenzialmente nessuna limite di espansione. Rispetto al database, quando tu metti una riga devi mettere tutti i valori, qua no, e metti una alla volta, Þ chiaro? Per ogni singolo nove puoi avere una cosa e poi avere un'altra. Questa Þ esperta, questa Þ perfetta, questo non ce l'ha, l'importante no.
Transcript: [2411.738 --> 2434.537]  quindi Þ esattamente un db e poi c'Þ questo di R-model, qui di R-model c'Þ questa notazione che vedono vecchissima e questi nodi, questo Þ l'equivalente della tabella, c'Þ tutta questa notazione che io non riesco mai a ricordare, perchÚ non so quanti usano per‗ in quegli aspetti non ce la usano, questa Þ la relazione e questo Þ un concetto esattamente come era
Transcript: [2444.29 --> 2472.674]  Quindi, in questo linguaggio qua, sono sempre triple. Di nuovo, perchÚ? PerchÚ noi sappiamo che un qualunque employee viene pagato con una certa quantitÓ di dollari. Un qualunque employee vive in una certa cittÓ. Qualunque persona o manager di employee. Sono tutte triple. Sono tutte associazioni. Sono tutte cose che sono vere o false. E ovviamente, se adesso andiamo al mondo moderno, dal 2010 in poi,
Transcript: [2473.012 --> 2500.94]  Non facciamo pi¨ di R-Modern ma facciamo i Knowledge Graphs chiamati E-Type Graphs, di cui faremo lezione. Ognuna di queste avrÓ una sua logica, intendendo per oggi un algoritmo di calcolo delle conseguenze. E' quella di prima, per‗ di nuovo, abbiamo questo Knowledge Graph, per‗ qui i nodi non sono pi¨ entity types. Gli nodi qua sono entity types. Le frecce sono sempre relazioni.
Transcript: [2501.446 --> 2530.758]  per‗ se io dico nel grafo precedente io qui dico che tutti e due hanno degli animali giusto no? per‗ magari qui potevo dire che Þ sdog cioÞ in questo grafo qui tu hai delle
Transcript: [2534.302 --> 2564.018]  a questo livello del Knowledge Graph tu non hai, come si vedrÓ nella BNF pi¨ avanti, alcun vincolo sui nomi di persone che usi, va bene, ma sul nome della proprietÓ, ok? Se io vado qui, io dico che tutte le persone potenzialmente hanno un posto messo in alto. Potenzialmente, perchÚ abbiamo detto che il Knowledge Graph, quindi diamo di fatto lo schema.
Transcript: [2564.66 --> 2589.078]  Diciamo che tutte le entitÓ di un po' persona possono avere, se lo so, perchÚ chiaramente magari non lo so, diciamo di non rappresentarlo, un place per dove sono nati. Quindi di fatto questo knowledge graph Þ l'equivalente dello schema dei database. Qual Þ la differenza? Come vedrete nei prossimi anni, che questa Þ una struttura adatta, quindi la posso dare
Transcript: [2589.719 --> 2617.107]  al mio era l'errore o chiunque, Þ una struttura dati, non Þ come l'IR model, per‗ Þ una struttura dati e io ti mando la struttura dati e ti dico, senti un po', ti mando questa struttura dati e questo Þ come io parlo e in effetti vedremo che pi¨ avanti nell'orange graph, la query Þ un orange graph come l'avete visto nei data made, altro non Þ che un e-type graph cioÞ Þ uno schema di grafo che tu devi riempire
Transcript: [2618.035 --> 2645.693]  questo Þ un knowledge graph che lo fai mappare su un organo dell'entitÓ e dici guarda un po' che tiro quelle che hanno dei valori e chiaramente puoi dire dammi tutte quelle che hanno questi valori, in certi momenti quando la fai Johnny DataVille e magari che so dove gli animali si chiamano qui tutto questo per dirvi che salvo che stiamo cambiando una notazione perchÚ stiamo andando da IAR model
Transcript: [2647.094 --> 2674.718]  e da podere tabellare knowledge graphs tutta questa roba qui del concetto della sezione l'avete visto e di fatto l'avete implicitamente sistematicamente usato fatto questo cos'Þ una sezione? una sezione Þ un elemento perchÞ a questo punto noi vogliamo dire che un linguaggio insieme al com
Transcript: [2675.528 --> 2701.28]  vuole dire che una sezione c'Þ una cosa o Þ vero o falso insieme del linguaggio e noi chiamiamo fatto quella percezione definita come abbiamo fatto la volta scorsa che Þ denotata dal linguaggio. Quindi a questo punto, ordinando la prossima varia, abbiamo detto che l'opinio era una tripla, c'era un alfabeto, no, scusate, c'era un
Transcript: [2703.507 --> 2731.604]  che sono tutte quelle affermazioni del mondo che sono vero o falso. Dato questo, uno in quattro, per ognuno dipende, la pronuncia dell'insieme dipende ti dÓ la sezione 1, la sezione 2 e la sezione 3. Quindi cosa sto dicendo io?
Transcript: [2732.077 --> 2761.152]  che volendo voi fate l'alfabeto, fate una columpia, viene fermata sicuramente per arrivare a costruire queste asserzioni che denotano le cose che si dovrebbero fare. Infatti, probabilmente, a questo punto vi avevo detto che c'erano sei tipi di fatti e c'erano sei tipi di asserzioni. La prima asserzione, come era nell'indice che Fausto Þ un uomo, la seconda asserzione
Transcript: [2761.507 --> 2783.596]  ci dice che Fausto Þ di fronte a tutti noi. La terza direzione ci dice, sotto insieme, che Þ una persona che muove una persona. Per ognuno delle sei forme, con cui noi descriviamo dei sei tipi di percezione di fatti,
Transcript: [2787.882 --> 2814.207]  Chiaramente, come vedremo, faremo una pausa matematica, dovremo dire che, diremo che dato una certa sezione, il valore di veritÓ della sezione sarÓ, e lo vedremo alla posta domani, sarÓ composto del valore di come si compongono i significati, no? CioÞ se io dico, ed ecco il senso, se io dico Fausto Þ a casa.
Transcript: [2818.831 --> 2847.13]  dove non Þ qui. Fausto Þ? Fausto Þ fisicamente dentro. PerchÚ questo descrive una situazione che nel mio mondo del modello c'Þ una certa casa a qualche parte mentre sono qua all'universitÓ. Quindi ora che ci stiamo costruendo tutto il linguaggio, e come ripeto non sto facendo niente di nuovo, domani definiamo questa funzione di interpretazione e a quel punto definire ci‗ che Þ vero e che Þ falso Þ algoritmo.
Transcript: [2848.818 --> 2878.366]  Ok? E da un modello di interpretazione posso dire se Þ vero o falso. E se poi io ti dico Fausto oggi Þ a casa o in ufficio o all'universitÓ, Þ vero perchÚ ce l'ho. Fausto Þ a casa e in ufficio Þ impossibile, non pu‗ essere nel bosco. E chiaramente questo non Þ vero. E chiaramente, adesso mi viene appunto la frisettina, ma chiaramente, come ho detto, il nodo
Transcript: [2878.872 --> 2903.324]  il knowledge graph dell'universitÓ a un livello di nodi, perchÞ il problema Þ scalato come prima, adesso vi segnalo le sezioni, questa Þ una sezione che ho giÓ detto prima, questa lo scriviamo in linguaggio fissimo-analogico e di fatto io penso che sia abbastanza ovvio, cos'Þ quindi
Transcript: [2904.05 --> 2931.623]  Questa Þ la teoria del mondo, se Þ vera, oppure la teoria falsa del mondo, se c'Þ anche una sola definizione che Þ falsa, ok? Voi fate questo, non fate che fare questo, questo Þ indipendente dal linguaggio che usate.
Transcript: [2932.012 --> 2957.189]  questa Þ la versione che sia teoretica che non mi piace niente quindi la salvo e questo Þ un esercizio andato un pochettino di esame quindi ho dato questo model graph e c'era da capire cosa diceva ovviamente Þ un model graph fatto da gente che non sa la logica e quindi ha tutte ogni freccia che ti permessi di guardare
Transcript: [2957.611 --> 2981.0]  perchÚ se tu prendi linguaggio naturale e non hai un modello di riferimento, ogni verbo diventa una freccia. Il risultato Þ che c'Þ 100.000 verbi. Quindi Þ strano il significato, ma ha dei problemi. Con cose piccole c'Þ una serie di domande da affrontare. Si potrebbe dire se una certa frase era vera o falsa.
Transcript: [2981.118 --> 3011.02]  una volta che hai imparato come costruire la tua interfaccia queste sezioni sono sezioni fra insieme, questo Þ il simbolo che faremo nella seconda logica che facciamo che vuol dire che semanticamente quando noi diremo cosa significa questo nel linguaggio vuol dire che a me ne sono sufficienti persone per darci il linguaggio
Transcript: [3011.442 --> 3033.076]  fa differenza fra questo e questo nessuno se non che probabilmente quando fai misioni questo Þ pi¨ facile da farci calcoli perchÚ sono tutte le date pi¨ veloci e ovviamente di nuovo sempre cosý questo Þ il WordNet
Transcript: [3034.308 --> 3062.557]  Questa Þ la terza logica che facciamo, la logica del linguaggio che Þ quella logica che ti dice in che modo il significato delle parole Þ legato al significato delle parole che ci sono sotto. Quindi un istrumento Þ un device
Transcript: [3064.902 --> 3090.721]  Ah, no, no, sý, un device... Ah, certo, certo, vedi, uno strumento Þ un device e uno strumento Þ un'entitÓ, i valori che dobbiamo usare. Di fatto, queste strutture d'arte, come stiamo a citare, sono strutture semantiche. Quando io qua dico che arti fatte di arti fatte in un modo un po' diverso, questa Þ la soluzione, sý, Þ come fare l'automobile.
Transcript: [3100.677 --> 3127.593]  Questa Zai dice niente di nuovo, quella che potete vedere ancora dice essenzialmente che il mapping lo fai come vuoi. Quindi a questo punto siamo passati, come ho detto prima, dal dominio visto tramite i percetti costitutivi al dominio visto con l'insieme dei fatti.
Transcript: [3128.521 --> 3147.387]  Dato questo, basta fare da linguaggio, costruire un mapping, dare assezioni all'insieme del fatto. E ci‗ che faccio Þ quello che c'Þ a domanda. Torno in piazza, dobbiamo appunto fondamentare che quando noi parliamo, parliamo sempre in termini di geometria.
Transcript: [3158.17 --> 3185.744]  Quando parli con i matematici, i matematici ti chiamano e ti dicono che questa Þ la versione intenzionale e questa Þ la versione estenzionale, questa Þ la versione intenzionale e questa Þ la versione estenzionale. ╚ come quando fate i satiri, che vi dicono un insieme, lo puoi definire estensionalmente una lista di elementi o intenzionalmente una funzione. Quando vi stanno parlando, due insiemi particolari, l'insieme della sezione e l'insieme dei fatti e dei dettagli.
Transcript: [3191.549 --> 3220.574]  A questo punto ci siamo dati il linguaggio. Essendoci dati il linguaggio, a questo punto ci siamo dati non solo il linguaggio, se pensate agli esempi del tabeschi ho fatto, l'ho scritto in linguaggio naturale su Brenner e cosý via, ci siamo dati un linguaggio dove in realtÓ tutte queste sentenze le possono scrivere uno dopo l'altro. Quindi questo linguaggio ci permette di dire 100 sentenze, 1000 sentenze.
Transcript: [3221.452 --> 3249.177]  insieme a quello che le sentenze che noi diciamo e che prendiamo come vere Þ la nostra teoria linguistica. E' esattamente quell'oggetto che nella seconda lezione abbiamo chiamato la prevenzione linguistica del mondo. Quindi a questo punto qualunque linguaggio che noi facciamo andiamo a riprodurre questa come una teoria, una teoria assenzionale
Transcript: [3249.7 --> 3274.152]  e l'ho chiamata teoria selezionale perchÞ Þ semplice ci‗ che fa, vedremo che nell'ultimo livello ne possiamo fare anche delle teorie che sono funzioni di cose non vere perchÞ quindi adesso nell'ultimo livello della teoria che Þ logica delle composizioni possiamo ragionare anche su ci‗ che non sappiamo nel logico del mondo noi parliamo di teorie selezionali
Transcript: [3274.388 --> 3303.295]  CioÞ noi, dato quello che sappiamo, possiamo dire quell'informazione che sappiamo deludere le nostre paese. Ma non possiamo deludere, non abbiamo abbastanza espressioni linguistiche nel linguaggio per dire quello che sappiamo. Ok? E questo Þ il passaggio fondamentale fra i valori 3 e i valori 4. Il problema dell'inconsistenza l'abbiamo affrontato la volta scorsa.
Transcript: [3307.615 --> 3334.328]  Abbiamo affrontato abbastanza la teoria dei modelli. Cosa vuol dire? Vuol dire che ricordate che le modelli sono mutuamente inconsistenti se entrambi i modelli, se i due modelli dicono una cosa non pu‗ essere nel mondo reale. Quindi vuol dire che il modello in cui io sono qui, io sono in un'altra parte insieme, non Þ un modello reale. Questa roba qui chiaramente la liftiamo all'interno della sezione.
Transcript: [3350.528 --> 3378.254]  a questo punto ci siamo dati
Transcript: [3378.929 --> 3405.187]  nel linguaggio di dire la possibilitÓ di dire che una teoria ha senso e non ha senso e questo Þ un tipico problema che c'Þ ad esempio nel database tanto che mediamente
Transcript: [3405.811 --> 3435.764]  Cos'Þ il database? Il database Þ un'attorea del mondo. E cos'Þ che succede? Ad un certo punto, al database, voglio aggiungere una sezione A. Questa sezione qui Þ l'attorea qua del mondo. ╚ consistente o inconsistente? Beh, nel database non c'Þ modo di sapere.
Transcript: [3436.473 --> 3464.063]  perchÞ, come Þ fatto, ad esempio io in T potrei avere due frase on, on, via giusto no? Þ abbastanza normale
Transcript: [3466.612 --> 3491.772]  che dite Þ possibile, ma la database non lo pu‗ fare. Per poterlo fare devi avere da qualche parte, ed Þ esattamente dove ci sono la logica, che O A B Þ solo se disjoint con O B A, ovvero sia
Transcript: [3496.008 --> 3522.569]  l'intersecato, il modello, il fatto che Þ denotato da Ovi e questo fatto qui, non sono possibili contemporaneamente. Ci dobbiamo dare questi simboli, che non sono dettabili. PerchÚ? PerchÚ i dettabili, come sarÓ nella nostra tecnologica, sono
Transcript: [3522.687 --> 3549.468]  sono linguaggi asserzionali dove puoi dire solamente quello che vedi, non puoi porre dei bigli. Ma tu, che ti viene da, ad esempio quando fai, come senza origini in AI, piuttosto che fai modelli di qualunque sistema, tu c'hai un sacco di condizioni, che sai e che non scrivi dei database. Chiaramente a questo punto hai due alternative, se fai come dei database
Transcript: [3549.805 --> 3570.612]  dove li metti in funzionalitÓ per cui tutto quello che sai Þ automaticamente verificato, oppure se li porti nel mondo aperto devi fare il motore di rischio che all'antanno decide. Provo a dire che comunque sia come
Transcript: [3571.895 --> 3598.574]  Nozione di guardiere di logica, ci siamo dati che cosa? Ci siamo dati che c'Þ tutto un meccanismo di rappresentare, quindi tutti abbiamo capito che quando noi parliamo di rappresentare rappresentiamo solo ci‗ che Þ vero e ci‗ che fa, sono l'unica cosa importante. Poi ci siamo dati un linguaggio per rappresentarlo, domani ci daremo la definizione formale di come si deve rappresentare. Il nostro tempo di rappresentazione Þ una cosa molto incerta per chi vuole sapere un esempio di algoritmo.
Transcript: [3598.76 --> 3628.257]  E ora ci stiamo andando a cominciare a vedere, che sarÓ esattamente fra due lezioni, come quando ci siamo dati questo linguaggio delle assenzioni, che si mappa uno a uno su quello che c'Þ nel mondo, possiamo cominciare a fare dei linguaggi dove ci cominciamo a dire quello che non vogliamo dire, o quello che vogliamo dire, quello che non vogliamo che succeda. Poi anche su tante cose possono succedere, pensate, cioÞ faccio un esempio, io sono qui, ma non sono a Roma, non sono a Milano, non sono a New York, non sono a 2087, io sono una cosa, non sono effettivamente un'altra cosa. L'informazione negativa Þ finita.
Transcript: [3629.641 --> 3658.345]  quindi queste logiche qui e non c'Þ modo di qualificarle nessuno le rende, per quanto faccia grosso non potrÓ mai qualificarle ci sono infinite relazioni infinite anche sulle parole noi con la logica, che Þ la logica che vediamo una volta che noi abbiamo un meccanismo di formalizzazione di questi principi che noi sappiamo vedere, il common sense knowledge noi potremmo fare degli algoritmi che
Transcript: [3658.835 --> 3687.742]  dato che questo lo faremo giÓ nella lezione tra di noi e gli altri cominceremo a fare quelle logiche che ci permettono di aggiungere a questa informazione che ci dice ci‗ che noi vediamo informazione aggiuntiva che impedisce all'algoritmo di dire ci‗ che dice e quindi qua dove siamo ora? e ovviamente qui non so perchÚ
Transcript: [3688.045 --> 3714.438]  E' un altro esempio? Ah certo, questa Þ quella di cercare esattamente quel punto e che ognuna, il punto di questo cosa fondamentale Þ che quello che noi percepiamo e quello che tutti i linguaggi della presentazione avevamo fatto prima, il nostro, Þ che non ti permette di dire una cosa.
Transcript: [3715.4 --> 3742.94]  Mi permettono di dire che Þ una sintasi che ti permette di fare le lingue infinitamente lunghe, puoi andare avanti in infinito, Þ intrinseco, Þ chiaro? Per‗ non puoi dire che in questi linguaggi, non puoi dire che fa un professore o... non puoi dire uno dei due, non ce la puoi dire, come non lo puoi dire a un'immagine, non c'Þ un'immagine che dice una cosa o l'altra, a massimo non la capisci, un'immagine ha sempre una sola interpretazione e questa dell'OO Þ esattamente quella di prima, questa esattamente
Transcript: [3743.48 --> 3771.239]  il motivo della logica. Protetto questo, la cosa fondamentale che costituisce il punto di partenza Þ che prima Þ importante capire che comunque sia tutto ci‗ che nel mondo io lo posso rappresentare con un linguaggio sezionale che Þ un linguaggio che definisce ci‗ che Þ vero e ci‗ che Þ falso. A seconda del linguaggio prima facevo una relazione fra entitÓ, ora faccio una relazione fra insieme semanticamente
Transcript: [3771.813 --> 3799.302]  insieme delle persone. Quale Þ interessante Þ che vedremo e diremo quante sono queste logiche, a parte la differenza dei tassi diversi, sono di nuovo 6. Quindi ci sono 6 tipi di osservazioni, ci sono 6 oggetti nel mondo differenti, ci sono 6 formi di osservazioni e ci sono 6
Transcript: [3801.58 --> 3827.23]  perchÚ se Þ sempre un fatto, ci sarÓ sicuramente un altro. E per lo meglio di questo facciamo la logica. E sarÓ la logica, questo prima, che ci permetterÓ di arrivare a dire con ci‗ che Þ vero nel mondo senza perdentici di dire ci‗ che non Þ vero nel mondo, non pu‗ essere vero nel mondo, non vogliamo che sia vero nel mondo. E questa sarÓ la lezione di giovedý prossimo.
Transcript: [3831.078 --> 3859.715]  Quindi a chiudere, come tu lo sai, perchÚ siamo andati tutti forti, la novitÓ carina di questa lezione, che concludiamo con un po' di anticipo, Þ che per ogni, assumendo che l'alternativa di insieme rappresenta il mondo, noi abbiamo per ogni oggetto che possiamo trovare in un'immagine, un oggetto nell'ingresso.
Transcript: [3864.052 --> 3884.875]  Domani scriveremo formalmente il passaggio da linguaggio all'oggetto del mondo e mezz'ora dopo cominceremo a fare il ragionamento e a vedere cosa vuol dire ragionare e fare ragionare su ci‗ che Þ vero e ci‗ che Þ falso. Ovvero sia, le dure conclusioni da quelle che sappiamo, perchÚ come vi ho detto prima,
Transcript: [3886.073 --> 3897.143]  fatto l'esempio del non, non vale per l'or, vale per l'en, vale per tutto, per una cosa che Þ vera c'Þ un numero infinito di cose che non sono vere, quindi il ragionamento serve esattamente perchÚ in qualunque approccio che vivi hai mancare tutte le veritÓ.
Downloading: "https://download.pytorch.org/torchaudio/models/wav2vec2_voxpopuli_base_10k_asr_it.pt" to C:\Users\matti/.cache\torch\hub\checkpoints\wav2vec2_voxpopuli_base_10k_asr_it.pt
2025-10-14 12:05:29 - whisperx.transcribe - INFO - Performing alignment...
2025-10-14 12:07:04 - whisperx.transcribe - WARNING - No --hf_token provided, needs to be saved in environment variable, otherwise will throw error loading diarization model
2025-10-14 12:07:04 - whisperx.transcribe - INFO - Performing diarization...
2025-10-14 12:07:04 - whisperx.transcribe - INFO - Using model: pyannote/speaker-diarization-3.1
2025-10-14 12:07:04 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1

Could not download 'pyannote/speaker-diarization-3.1' pipeline.
It might be because the pipeline is private or gated so make
sure to authenticate. Visit https://hf.co/settings/tokens to
create your access token and retry with:

   >>> Pipeline.from_pretrained('pyannote/speaker-diarization-3.1',
   ...                          use_auth_token=YOUR_AUTH_TOKEN)

If this still does not work, it might be because the pipeline is gated:
visit https://hf.co/pyannote/speaker-diarization-3.1 to accept the user conditions.
